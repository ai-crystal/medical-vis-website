import{_ as a,c as s,a as t,b as i,r as n,o as l}from"./app-qAZDVKNQ.js";const u="/images/publications/NNFF_01.png",m="/images/publications/NNFF_02.png",p="/images/publications/NNFF_03.png",c="/images/publications/NNFF_04.png",d={},g={class:"hint-container note"},h={class:"hint-container-title"};function f(v,e){const o=n("VPIcon"),r=n("ArtPlayer");return l(),s("div",null,[t("div",g,[t("p",h,[i(o,{provider:"iconify",name:"ci:book-open"})]),e[0]||(e[0]=t("p",null,"Xu, C., Xu, X., Zhang, J., Liu, Y., Cao, Y. and Zhao, L. (2025), Real-time Neural Denoising for Volume Rendering Using Dual-Input Feature Fusion Network. Computer Graphics Forum e70276. https://doi.org/10.1111/cgf.70276",-1))]),e[1]||(e[1]=t("p",null,"Direct volume rendering (DVR) is a widely-used technique in the visualization of volumetric data. As an important DVR technique, volumetric path tracing (VPT) simulates light transport to produce realistic rendering results, which provides enhanced perception and understanding for users, especially in the field of medical imaging. VPT, based on the Monte Carlo (MC) method, typically requires a large number of samples to generate noise-free results. However, in real-time applications, only a limited number of samples per pixel is allowed and significant noise can be created.",-1)),e[2]||(e[2]=t("p",null,"This paper introduces a novel neural denoising approach that utilizes a new feature fusion method for VPT. Our method uses a feature decomposition technique that separates radiance into components according to noise levels. Our new decomposition technique mitigates biases found in the contemporary decoupling denoising algorithm and better utilizes of samples. A lightweight dual-input network is designed to correlate these components with noise-free ground truth. Additionally, for denoising sequences of video frames, we develop a learning-based temporal method that calculates temporal weight maps, blending reprojected results of previous frames with spatially denoised current frames. Comparative results demonstrate that our network performs faster inference than existing methods and can produce denoised output of higher quality in real time.",-1)),e[3]||(e[3]=t("img",{src:u},null,-1)),i(r,{src:"https://drive.threekd.com/?file=medical-vis-website/videos/publications/NNFF_01.mp4",fullscreen:""}),e[4]||(e[4]=t("img",{src:m},null,-1)),e[5]||(e[5]=t("img",{src:p},null,-1)),e[6]||(e[6]=t("img",{src:c},null,-1))])}const N=a(d,[["render",f]]),y=JSON.parse('{"path":"/medical-vis/Publications/NNFF.html","title":"Real-time realistic direct volume rendering using neural noisy feature fusion","lang":"en-US","frontmatter":{"title":"Real-time realistic direct volume rendering using neural noisy feature fusion","tags":[null],"PageLayout":"custom","navbar":true,"aside":false,"outline":[2,4],"description":"Xu, C., Xu, X., Zhang, J., Liu, Y., Cao, Y. and Zhao, L. (2025), Real-time Neural Denoising for Volume Rendering Using Dual-Input Feature Fusion Network. Computer Graphics Forum...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Real-time realistic direct volume rendering using neural noisy feature fusion\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://www.medical-vis.com/medical-vis/Publications/NNFF.html"}],["meta",{"property":"og:site_name","content":"medical-vis"}],["meta",{"property":"og:title","content":"Real-time realistic direct volume rendering using neural noisy feature fusion"}],["meta",{"property":"og:description","content":"Xu, C., Xu, X., Zhang, J., Liu, Y., Cao, Y. and Zhao, L. (2025), Real-time Neural Denoising for Volume Rendering Using Dual-Input Feature Fusion Network. Computer Graphics Forum..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}]]},"git":{"createdTime":1760370562000},"autoDesc":true,"filePathRelative":"medical-vis/Publications/NNFF.md","headers":[]}');export{N as comp,y as data};
